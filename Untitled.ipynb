{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "known-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "remarkable-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exceptional-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_for_url = \"https://www.sports-reference.com/cbb/seasons/2023-school-stats.html\"\n",
    "basic_against_url = \"https://www.sports-reference.com/cbb/seasons/2023-opponent-stats.html\"\n",
    "adv_for_url = \"https://www.sports-reference.com/cbb/seasons/2023-advanced-school-stats.html\"\n",
    "adv_against_url = \"https://www.sports-reference.com/cbb/seasons/2023-advanced-opponent-stats.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spatial-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stats_table(url):\n",
    "    # Takes in url as paramter -> scrapes html -> returns pandas dataframe\n",
    "    req = requests.get(url)\n",
    "    res = req.content\n",
    "    df = pd.read_html(res, attrs={\"class\":\"stats_table\"})[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varying-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tables\n",
    "basic_for = scrape_stats_table(basic_for_url)\n",
    "basic_against = scrape_stats_table(basic_against_url)\n",
    "adv_for = scrape_stats_table(adv_for_url)\n",
    "adv_against = scrape_stats_table(adv_against_url)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specified-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of basic stats column names to use in cleaned data frames\n",
    "# combining both index levels in column names for 'non-unique' columns\n",
    "basic_col_names =  []\n",
    "for col in basic_for.columns:\n",
    "    if not any(c in col[0] for c in ['Totals', 'Unnamed']):\n",
    "        col_name = col[0] + col[1]\n",
    "        basic_col_names.append(col_name)\n",
    "    else:\n",
    "        col_name = col[1]\n",
    "        basic_col_names.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of advanced stats column names to use in cleaned data frames\n",
    "# essentially the same logic as above\n",
    "adv_col_names = []\n",
    "for col in adv_against.columns:\n",
    "    if not any(c in col[0] for c in ['Advanced', 'Unnamed']):\n",
    "        col_name = col[0] + col[1]\n",
    "        adv_col_names.append(col_name)\n",
    "    else:\n",
    "        col_name = col[1]\n",
    "        adv_col_names.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "peaceful-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_frame(df, stat_type):\n",
    "    \n",
    "    # renaming columns and then dropping the 'Unnamed' ones\n",
    "    if stat_type == 'adv':\n",
    "        df.columns = adv_col_names\n",
    "    else:\n",
    "        df.columns = basic_col_names\n",
    "    df = df.loc[:,~df.columns.str.startswith('Unnamed')]\n",
    "    \n",
    "    # dropping extra header rows\n",
    "    df.drop(df[(df['OverallG'] == 'Overall') | (df['OverallG'] == 'G')].index, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "integral-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: find way to get top 25 rankings\n",
    "poll_url = \"https://www.sports-reference.com/cbb/seasons/2023-polls.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "resistant-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "poll = pd.read_html(poll_url, attrs={\"class\":\"poll\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "toxic-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: find way to get conference for each school\n",
    "conference_url = 'https://www.sports-reference.com/cbb/seasons/2023-standings.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "preliminary-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conferences(url):\n",
    "    req = requests.get(url)\n",
    "    res = req.content\n",
    "    soup = BeautifulSoup(res, 'lxml')\n",
    "    return soup          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "permanent-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_soup = get_conferences(conference_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "nonprofit-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_conferences():\n",
    "    table_list = []\n",
    "    divs = conferences_soup.find_all('div', attrs={'class':'table_wrapper'})\n",
    "    for div in divs:\n",
    "        for element in div(text = lambda text: isinstance(text, Comment)):\n",
    "            element.extract()\n",
    "            table = pd.read_html(element)\n",
    "            table_list.append(table)\n",
    "    return table_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "premier-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = clean_conferences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bright-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = []\n",
    "for item in conferences:\n",
    "    df_item = item[0]\n",
    "    df = pd.DataFrame(df_item)\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    conf_df = pd.DataFrame(df[['School','Conf']])\n",
    "    conf_list.append(conf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "invisible-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe from list\n",
    "conf_df = pd.concat(conf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eligible-theater",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "basic_for_clean = clean_data_frame(basic_for, 'basic')\n",
    "basic_against_clean = clean_data_frame(basic_against, 'basic')\n",
    "adv_for_clean = clean_data_frame(adv_for, 'adv')\n",
    "adv_against_clean = clean_data_frame(adv_against, 'adv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "selective-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding current poll rankings to cleaned data frames\n",
    "basic_for_clean = basic_for_clean.merge(poll[['School','Rk']], how='left', on='School', suffixes=('_stats','_poll'))\n",
    "basic_against_clean = basic_against_clean.merge(poll[['School','Rk']], how='left', on='School', suffixes=('_stats','_poll'))\n",
    "adv_for_clean = adv_for_clean.merge(poll[['School','Rk']], how='left', on='School', suffixes=('_stats','_poll'))\n",
    "adv_against_clean = adv_against_clean.merge(poll[['School','Rk']], how='left', on='School', suffixes=('_stats','_poll')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fifty-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding conferences to cleaned data frames\n",
    "basic_for_clean = basic_for_clean.merge(conf_df, how='left', on='School')\n",
    "basic_against_clean = basic_against_clean.merge(conf_df, how='left', on='School')\n",
    "adv_for_clean = adv_for_clean.merge(conf_df, how='left', on='School')\n",
    "adv_against_clean = adv_against_clean.merge(conf_df, how='left', on='School')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "historic-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting to Excel to then import to Tableau\n",
    "writer = pd.ExcelWriter('~/desktop/data/python/ncaa_bb/data.xlsx')\n",
    "basic_for_clean.to_excel(writer, 'basic_for')\n",
    "basic_against_clean.to_excel(writer, 'basic_against')\n",
    "adv_for_clean.to_excel(writer, 'adv_for')\n",
    "adv_against_clean.to_excel(writer, 'adv_against')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-luther",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
